{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ed5bc5017c3fb04814a932759475882729cab95ed5b05095733f3a83ad7fc497"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Summary-like from Tensorflow\n",
    "from torchsummary import summary\n",
    "\n",
    "# Import Numpy\n",
    "import numpy as np\n",
    "# Plot Import\n",
    "import matplotlib.pyplot as plt\n",
    "# For timer\n",
    "import time\n",
    "# Import OS\n",
    "import os\n",
    "# import local libs\n",
    "import ecg_tools_lite as et\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "# WFDB\n",
    "import wfdb\n",
    "\n",
    "if not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device: cuda 11 / 27 / 2020\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "device = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Device:\", device, time.localtime().tm_mon, \"/\", time.localtime().tm_mday, \"/\", time.localtime().tm_year)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Printing fields information of the signal: \n{'fs': 360, 'sig_len': 650000, 'n_sig': 1, 'base_date': None, 'base_time': None, 'units': ['mV'], 'sig_name': ['V1'], 'comments': [\"Created by `nst' from records 118 and em (SNR = 6 dB)\"]}\n"
     ]
    }
   ],
   "source": [
    "ecg_whole = et.load_signal('118e06', '', v_fields=True, channel=1) # Creates an array of the entire thing\n",
    "ecg_loader = DataLoader( ecg_whole, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "source": [
    "ecg_clean = et.load_ecg_file('all_chunks_fs1024_e24.npy')\n",
    "ecg_noisy = et.load_ecg_file('all_chunks_fs1024_e06.npy')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_array_pos = 0\n",
    "end_array_pos = 1000\n",
    "\n",
    "# add double().to(device) to move the data to GPU\n",
    "noise_set = torch.from_numpy(ecg_noisy).double().to(device)\n",
    "clean_set = torch.from_numpy(ecg_clean).double().to(device)\n",
    "\n",
    "# Combined dataset of noise + clean on a single dataset will be used with enumerate\n",
    "combined_dataset = torch.utils.data.TensorDataset( noise_set, clean_set) # CPU version\n",
    "trainloader = DataLoader( combined_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "source": [
    "# kernel_size = (16,)\n",
    "# padding_size= int( kernel_size[0]/2 ) # If odd, add -1\n",
    "\n",
    "# class ae_sampler(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ae_sampler, self).__init__()\n",
    "\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Conv1d(1024, 40, kernel_size, stride=2, padding=padding_size),\n",
    "#             nn.ELU(True),   \n",
    "#             nn.Conv1d(40, 20, kernel_size, stride=2, padding=padding_size),\n",
    "#             nn.ELU(True),   \n",
    "#             nn.Conv1d(20, 20, kernel_size, stride=2, padding=padding_size),\n",
    "#             nn.ELU(True),\n",
    "#             # nn.Conv1d(20, 20, kernel_size, stride=2, padding=padding_size),\n",
    "#             # nn.ELU(True),   \n",
    "#             # nn.Conv1d(20, 40, kernel_size, stride=2, padding=padding_size),\n",
    "#             # nn.ELU(True),   \n",
    "#             # nn.Conv1d(40, 1, kernel_size, stride=1, padding=padding_size),\n",
    "#             # nn.ELU(True),   \n",
    "#         )\n",
    "\n",
    "#         self.decoder = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(1, 40, kernel_size, stride=1),\n",
    "#             # nn.ConvTranspose1d(40, 20, kernel_size, stride=2),\n",
    "#             # nn.ConvTranspose1d(20, 20, kernel_size, stride=2),\n",
    "#             # nn.ConvTranspose1d(20, 20, kernel_size, stride=2),\n",
    "#             # nn.ConvTranspose1d(20, 40, kernel_size, stride=2),\n",
    "#             nn.ConvTranspose1d(40, 1024, kernel_size, stride=2),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.encoder(x)\n",
    "#         x = self.decoder(x)\n",
    "\n",
    "#         return x"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "temp = kernel_size * 40\n",
    "print( temp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = (16,)\n",
    "padding_size= int( kernel_size[0]/2 ) # If odd, add -1\n",
    "\n",
    "class ae_sampler(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ae_sampler, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1024, 40, kernel_size, stride=2, padding=padding_size),\n",
    "            \n",
    "            nn.ELU(True),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(1, 40, kernel_size, stride=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model, trainloader, epochs):\n",
    "#     elapsed_start = time.time()\n",
    "#     train_loss = []\n",
    "#     criterion = nn.MSELoss().cuda()\n",
    "#     optimizer = torch.optim.Adam( model.parameters(), lr=1e-3 )\n",
    "    \n",
    "#     for epoch in range(epochs):\n",
    "#         # Running loss computed at the end\n",
    "#         running_loss = 0.0        \n",
    "#         # start timer\n",
    "#         epoch_start = time.time()\n",
    "#         # Loop through the entire dataset\n",
    "#         for i, (noise_sig, clean_sig) in enumerate(trainloader):\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "#             x_prime = model( noise_sig )\n",
    "            \n",
    "#             loss = criterion( x_prime, clean_sig) # or loss function\n",
    "            \n",
    "#             # Backpropagation\n",
    "#             loss.backward()\n",
    "            \n",
    "#             optimizer.step()\n",
    "#             running_loss += loss.item()\n",
    "        \n",
    "#             loss = running_loss / len(trainloader)\n",
    "        \n",
    "#             train_loss.append(loss)\n",
    "\n",
    "#         # ===== Epoch timer =====\n",
    "#         epoch_end = time.time()\n",
    "#         time_total = epoch_end - epoch_start\n",
    "#         print( f\"Epoch {epoch+1} of 2 || time: {time_total:.2f} || loss = {loss}\")\n",
    "#         # ===== Total training elapsed time =====\n",
    "#     elapsed_end = time.time()\n",
    "#     elapsed_total = elapsed_end-elapsed_start\n",
    "#     elapsed_mins = int(elapsed_total/60)\n",
    "#     elapsed_secs = int(elapsed_total - (60 * elapsed_mins))\n",
    "#     print(f'Elapsed time: {elapsed_total:.2f}, (in mins: {elapsed_mins}:{elapsed_secs})')\n",
    "\n",
    "#     return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, epochs):\n",
    "    elapsed_start = time.time()\n",
    "    train_loss = []\n",
    "    criterion = nn.MSELoss().cuda()\n",
    "    optimizer = torch.optim.Adam( model.parameters(), lr=1e-3 )\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Running loss computed at the end\n",
    "        running_loss = 0.0        \n",
    "        # start timer\n",
    "        epoch_start = time.time()\n",
    "        # Loop through the entire dataset\n",
    "        for i, noise_sig in enumerate(trainloader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            one_sig = noise_sig.view( noise_sig.shape[0], noise_sig.shape[1], 1)\n",
    "            x_prime = model( one_sig )\n",
    "            \n",
    "            loss = criterion( x_prime, one_sig) # or loss function\n",
    "            \n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            loss = running_loss / len(trainloader)\n",
    "        \n",
    "            train_loss.append(loss)\n",
    "\n",
    "        # ===== Epoch timer =====\n",
    "        epoch_end = time.time()\n",
    "        time_total = epoch_end - epoch_start\n",
    "        print( f\"Epoch {epoch+1} of 2 || time: {time_total:.2f} || loss = {loss}\")\n",
    "        # ===== Total training elapsed time =====\n",
    "    elapsed_end = time.time()\n",
    "    elapsed_total = elapsed_end-elapsed_start\n",
    "    elapsed_mins = int(elapsed_total/60)\n",
    "    elapsed_secs = int(elapsed_total - (60 * elapsed_mins))\n",
    "    print(f'Elapsed time: {elapsed_total:.2f}, (in mins: {elapsed_mins}:{elapsed_secs})')\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [40, 1024, 16], expected input[1024, 1, 1] to have 1024 channels, but got 1 channels instead",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-fda39ee24ba2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mae_sampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mecg_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# train_model( ae_sampler, noiseloader, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-c9454a5e876e>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, trainloader, epochs)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mone_sig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnoise_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnoise_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mx_prime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mone_sig\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mx_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_sig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# or loss function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\laure\\Developer\\pyenv-1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-3930c2eabc26>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\laure\\Developer\\pyenv-1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\laure\\Developer\\pyenv-1\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\laure\\Developer\\pyenv-1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\laure\\Developer\\pyenv-1\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    256\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m--> 258\u001b[1;33m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0m\u001b[0;32m    259\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [40, 1024, 16], expected input[1024, 1, 1] to have 1024 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "model = ae_sampler().cuda()\n",
    "model.double()\n",
    "losses = train_model( model, ecg_loader, 2)\n",
    "# train_model( ae_sampler, noiseloader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.encoder(noise_set)\n",
    "x = model.decoder(x)\n",
    "x = x.cpu()\n",
    "x = x.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\n├─Sequential: 1-1                        --\n|    └─Conv1d: 2-1                       655,400\n|    └─ELU: 2-2                          --\n├─Sequential: 1-2                        --\n|    └─ConvTranspose1d: 2-3              656,384\n=================================================================\nTotal params: 1,311,784\nTrainable params: 1,311,784\nNon-trainable params: 0\n=================================================================\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Sequential: 1-1                        --\n",
       "|    └─Conv1d: 2-1                       655,400\n",
       "|    └─ELU: 2-2                          --\n",
       "├─Sequential: 1-2                        --\n",
       "|    └─ConvTranspose1d: 2-3              656,384\n",
       "=================================================================\n",
       "Total params: 1,311,784\n",
       "Trainable params: 1,311,784\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape is too large -> (5842, 1024, 16)\n"
     ]
    }
   ],
   "source": [
    "index_chk = 0\n",
    "clean_set_cpu = clean_set.cpu()\n",
    "if x.shape[2] == 1:\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.plot( clean_set_cpu[index_chk], c='green' )\n",
    "    plt.plot( x[index_chk], c='red' )\n",
    "else:\n",
    "    print(f\"Shape is too large -> {x.shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_sig_to_numpy(input_sig):\n",
    "#     temp_sig = input_sig\n",
    "#     temp_sig = temp_sig.view( temp_sig.shape[1], 1)\n",
    "#     temp_sig = temp_sig.cpu()\n",
    "#     temp_sig = temp_sig.detach().numpy()\n",
    "#     return temp_sig\n",
    "\n",
    "# for i, (noise_sig, clean_sig) in enumerate(trainloader):\n",
    "#     temp_sig_noise = convert_sig_to_numpy(noise_sig)\n",
    "#     temp_sig_clean = convert_sig_to_numpy(clean_sig)\n",
    "\n",
    "#     plt.figure(figsize=(20,5))\n",
    "#     plt.plot( temp_sig_clean )\n",
    "#     plt.plot( temp_sig_noise )\n",
    "#     if i == 1:\n",
    "#         break"
   ]
  }
 ]
}