{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ed5bc5017c3fb04814a932759475882729cab95ed5b05095733f3a83ad7fc497"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Pytorch Practice"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "# For timer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([5.3000, 3.0000])\ntensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]], dtype=torch.float64)\ntorch.Size([5, 3])\ntorch.Size([5, 3])\ntensor([[2., 2., 2.],\n        [2., 2., 2.],\n        [2., 2., 2.],\n        [2., 2., 2.],\n        [2., 2., 2.]], dtype=torch.float64)\n\nResult= \ntensor([[2., 2., 2.],\n        [2., 2., 2.],\n        [2., 2., 2.],\n        [2., 2., 2.],\n        [2., 2., 2.]])\n\nResult (in place addition) = \ntensor([[2.3823, 2.1374, 2.2881],\n        [2.3822, 2.0662, 2.3315],\n        [2.7880, 2.7541, 2.7067],\n        [2.0142, 2.5826, 2.6406],\n        [2.2043, 2.9190, 2.9361]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor( [5.3, 3])\n",
    "print( x )\n",
    "\n",
    "x = x.new_ones(5, 3, dtype=torch.double)\n",
    "print( x )\n",
    "\n",
    "# x = torch.rand_like(x, dtype=torch.float)\n",
    "# print( x )\n",
    "\n",
    "print( x.size() )\n",
    "print( x.shape )\n",
    "print( x+x)\n",
    "\n",
    "result = torch.zeros(5,3)\n",
    "torch.add(x,x, out=result)\n",
    "print(\"\\nResult= \\n\" + str(result) )\n",
    "result.add_( torch.rand_like(x))\n",
    "print(\"\\nResult (in place addition) = \\n\" + str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-1.3491,  1.0726,  0.5579,  0.2897],\n        [-0.7006, -0.0612, -1.8959,  0.9481],\n        [-1.0205, -0.3404,  1.6546, -0.0442],\n        [-1.0541,  2.0118, -0.2435, -0.4460]])\ntensor([[-1.3491,  1.0726],\n        [ 0.5579,  0.2897],\n        [-0.7006, -0.0612],\n        [-1.8959,  0.9481],\n        [-1.0205, -0.3404],\n        [ 1.6546, -0.0442],\n        [-1.0541,  2.0118],\n        [-0.2435, -0.4460]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,4)\n",
    "print(x)\n",
    "y = x.view(8,2) # kapalit ng x.reshape sa np/tf\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.7989],\n        [0.4230]])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.42301666736602783"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "x = torch.rand(2,1)\n",
    "print(x)\n",
    "x[1,0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n[1. 1. 1. 1. 1.]\ntensor([2., 2., 2., 2., 2.])\n[2. 2. 2. 2. 2.]\ntensor([4., 4., 4., 4., 4.])\ntensor([2., 2., 2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "# Numpy\n",
    "a = torch.ones(5)\n",
    "print( a )\n",
    "\n",
    "b = a.numpy()\n",
    "print( b )\n",
    "\n",
    "a.add_(torch.ones(5) ) # add in place modifies the memory accessed by a and b\n",
    "print( a )\n",
    "print( b )\n",
    "\n",
    "a = torch.add(a, a)\n",
    "print( a )\n",
    "\n",
    "c = torch.from_numpy(b)\n",
    "print( c )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1.2821, 1.0387, 1.8631],\n        [1.1112, 1.0613, 1.2154],\n        [1.0653, 1.7064, 1.4318],\n        [1.7786, 1.1916, 1.5401],\n        [1.3237, 1.2812, 1.5903]], device='cuda:0')\ntensor([[1.2821, 1.0387, 1.8631],\n        [1.1112, 1.0613, 1.2154],\n        [1.0653, 1.7064, 1.4318],\n        [1.7786, 1.1916, 1.5401],\n        [1.3237, 1.2812, 1.5903]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# CUDA TEST\n",
    "\n",
    "x = torch.rand(5,3)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    y = torch.ones_like(x, device=device)\n",
    "    x = x.to(device)\n",
    "    z = x + y\n",
    "    print( z ) \n",
    "    print(z.to(\"cpu\", torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 1.],\n        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones( 2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[3., 3.],\n        [3., 3.]], grad_fn=<AddBackward0>)\n<AddBackward0 object at 0x000002E87D9920D0>\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print( y )\n",
    "\n",
    "print( y.grad_fn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[27., 27.],\n        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print( z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[4.5000, 4.5000],\n        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "out.backward()\n",
    "print(x.grad)\n"
   ]
  },
  {
   "source": [
    "# Torch NN\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Net(\n  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n  (fc1): Linear(in_features=576, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10\ntorch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print ( len(params) )\n",
    "print( params[3].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.1287,  0.0117,  0.0369, -0.0985, -0.0120, -0.0466, -0.0334, -0.1315,\n          0.0392, -0.0204]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.1339,  0.0268,  0.0065, -0.1150, -0.0214, -0.0425, -0.0435, -0.1423,\n         -0.0018,  0.0036]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    input = torch.randn(1, 1, 32, 32)    \n",
    "    input = input.to(device)\n",
    "    net.to(device)\n",
    "    out = net(input)    \n",
    "    print(out)"
   ]
  },
  {
   "source": [
    "# Autoencoder test on Pytorch\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "if not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch [1/20], loss:0.1164, MSE_loss:0.0358\n",
      "Epoch run time: 12.65\n",
      "epoch [2/20], loss:0.0827, MSE_loss:0.0250\n",
      "Epoch run time: 12.85\n",
      "epoch [3/20], loss:0.0822, MSE_loss:0.0249\n",
      "Epoch run time: 12.75\n",
      "epoch [4/20], loss:0.0670, MSE_loss:0.0201\n",
      "Epoch run time: 12.78\n",
      "epoch [5/20], loss:0.0669, MSE_loss:0.0202\n",
      "Epoch run time: 12.80\n",
      "epoch [6/20], loss:0.0601, MSE_loss:0.0179\n",
      "Epoch run time: 12.79\n",
      "epoch [7/20], loss:0.0587, MSE_loss:0.0177\n",
      "Epoch run time: 12.77\n",
      "epoch [8/20], loss:0.0577, MSE_loss:0.0173\n",
      "Epoch run time: 12.76\n",
      "epoch [9/20], loss:0.0524, MSE_loss:0.0157\n",
      "Epoch run time: 12.79\n",
      "epoch [10/20], loss:0.0559, MSE_loss:0.0168\n",
      "Epoch run time: 12.81\n",
      "epoch [11/20], loss:0.0523, MSE_loss:0.0157\n",
      "Epoch run time: 12.80\n",
      "epoch [12/20], loss:0.0543, MSE_loss:0.0161\n",
      "Epoch run time: 12.86\n",
      "epoch [13/20], loss:0.0552, MSE_loss:0.0164\n",
      "Epoch run time: 12.77\n",
      "epoch [14/20], loss:0.0584, MSE_loss:0.0172\n",
      "Epoch run time: 12.77\n",
      "epoch [15/20], loss:0.0505, MSE_loss:0.0149\n",
      "Epoch run time: 12.93\n",
      "epoch [16/20], loss:0.0491, MSE_loss:0.0145\n",
      "Epoch run time: 12.86\n",
      "epoch [17/20], loss:0.0496, MSE_loss:0.0149\n",
      "Epoch run time: 12.82\n",
      "epoch [18/20], loss:0.0535, MSE_loss:0.0158\n",
      "Epoch run time: 12.85\n",
      "epoch [19/20], loss:0.0510, MSE_loss:0.0149\n",
      "Epoch run time: 13.14\n",
      "epoch [20/20], loss:0.0479, MSE_loss:0.0142\n",
      "Epoch run time: 13.15\n",
      "Total elapsed time: 256.93, (in minutes   4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def to_img(x):\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "def add_noise(img):\n",
    "    noise = torch.randn(img.size()) * 0.2\n",
    "    noisy_img = img + noise\n",
    "    return noisy_img\n",
    "\n",
    "\n",
    "def plot_sample_img(img, name):\n",
    "    img = img.view(1, 28, 28)\n",
    "    save_image(img, './sample_{}.png'.format(name))\n",
    "\n",
    "\n",
    "def min_max_normalization(tensor, min_value, max_value):\n",
    "    min_tensor = tensor.min()\n",
    "    tensor = (tensor - min_tensor)\n",
    "    max_tensor = tensor.max()\n",
    "    tensor = tensor / max_tensor\n",
    "    tensor = tensor * (max_value - min_value) + min_value\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def tensor_round(tensor):\n",
    "    return torch.round(tensor)\n",
    "\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda tensor:min_max_normalization(tensor, 0, 1)),\n",
    "    transforms.Lambda(lambda tensor:tensor_round(tensor))\n",
    "])\n",
    "\n",
    "dataset = MNIST('./data', transform=img_transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 28 * 28),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = autoencoder().cuda()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "# # Added elapsed timer\n",
    "# elapsed_start = time.time()\n",
    "# for epoch in range(num_epochs):\n",
    "#     epoch_start = time.time()\n",
    "#     for data in dataloader:\n",
    "#         img, _ = data\n",
    "#         img = img.view(img.size(0), -1)\n",
    "#         noisy_img = add_noise(img)\n",
    "#         noisy_img = Variable(noisy_img).cuda()\n",
    "#         img = Variable(img).cuda()\n",
    "#         # ===================forward=====================\n",
    "#         output = model(noisy_img)\n",
    "#         loss = criterion(output, img)\n",
    "#         MSE_loss = nn.MSELoss()(output, img)\n",
    "#         # ===================backward====================\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     # ===================log========================\n",
    "#     print('epoch [{}/{}], loss:{:.4f}, MSE_loss:{:.4f}'\n",
    "#           .format(epoch + 1, num_epochs, loss.data.item(), MSE_loss.data.item()\n",
    "#           )\n",
    "#           )\n",
    "#     epoch_end = time.time()\n",
    "#     print(\"Epoch run time: %.2f\" %(epoch_end-epoch_start))\n",
    "#     if epoch % 10 == 0:\n",
    "#         x = to_img(img.cpu().data)\n",
    "#         x_hat = to_img(output.cpu().data)\n",
    "#         x_noisy = to_img(noisy_img.cpu().data)\n",
    "#         weights = to_img(model.encoder[0].weight.cpu().data)\n",
    "#         save_image(x, './mlp_img/x_{}.png'.format(epoch))\n",
    "#         save_image(x_hat, './mlp_img/x_hat_{}.png'.format(epoch))\n",
    "#         save_image(x_noisy, './mlp_img/x_noisy_{}.png'.format(epoch))\n",
    "#         save_image(weights, './filters/epoch_{}.png'.format(epoch))\n",
    "\n",
    "# elapsed_end = time.time()\n",
    "# elapsed_total = elapsed_end-elapsed_start\n",
    "# print(\"Total elapsed time: %.2f, (in minutes %3d)\" %(elapsed_total, (elapsed_total/60)))\n",
    "\n",
    "# torch.save(model.state_dict(), './sim_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "model = autoencoder().cuda()\n",
    "model.load_state_dict(torch.load( './sim_autoencoder.pth' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=256, out_features=784, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([256, 784])\n"
     ]
    }
   ],
   "source": [
    "params = list( model.parameters() )\n",
    "print( params[0].size() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=256, out_features=784, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": []
  }
 ]
}